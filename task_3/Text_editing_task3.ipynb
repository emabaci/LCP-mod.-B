{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0dcefd",
   "metadata": {},
   "source": [
    "(Under the healine)$\\newline$\n",
    "\n",
    "Group: 2216\n",
    "\n",
    "Detection of pattern in disturbed timeseries.\n",
    "We chose to skip the creation of new data and used the data generated during class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd67371",
   "metadata": {},
   "source": [
    "(Under the plots of varying amplitude)$\\newline$\n",
    "From the above one clearly sees that the accurcay of the model increases with an increasing amplitude. This is because an increased amplitude, gives an increased signal to noise ratio. Hence the original pattern is more easily detectable in the data, and the model is capable of learning much faster. Reducing the original ratio by factor of 10 yields a dramatic difference where the weights of the model are not able to converge at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b923c53",
   "metadata": {},
   "source": [
    "Change the headline of the comparison of data plots to:$\\newline$\n",
    "Comparison of original vs. predicted data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79057ac",
   "metadata": {},
   "source": [
    "(Under the plots of L1) $\\newline$\n",
    "\n",
    "From the plots one can tell that an optimal value of lambda in the case of Lasso regularization is in the interval $\\lambda \\in \\left[0.0001,0.1\\right]$, as this yields the best classifications and lowest loss. One can also see that with an increasing value of lambda, the value of the weights of the filters decrease due to the stronger regularization. The magnitude of the bias however stays the same, as the regularization is performed only on the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d0c977",
   "metadata": {},
   "source": [
    "(Under the plots of L2) $\\newline$\n",
    "The results show that the optimal value of lambda for the L2-regularization is between 0.001 and 0.01. We see the same effect of lambda on the weights in the filters as before, that they decrease with increasing lambda. In the case where lambda is set to 10, the values of the weights are very low, but this also yields the lowest accuracy among the different lambda values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea683f",
   "metadata": {},
   "source": [
    "(Under the plots of comparsion between L1 and L2)$\\newline$\n",
    "\n",
    "The grid search gives a somewhat surprising result, that the optimal combination of the l1 and l2 $\\lambda$-paramters are 0.01 and 10 respectively. Confirming that the best value of $\\lambda$ for the combination of the two methods is not necessarily the same as the optimal values for the two methods on their own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3c104",
   "metadata": {},
   "source": [
    "(Under the variation of architecture)$\\newline$\n",
    "With the best model from last year we were surprised to find that it did not work well with our data at all. The model is struggeling to converge, and is very unstable. Early stopping had to be implemented for the loss not to reach unplottable values. We have investigated with and without different regularizers and initializers, but the model does not converge to a good accurcay in our runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2b40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
